\documentclass{article}

\input{config.tex}

\begin{document}

\begin{titlepage}
    \centering
    \includegraphics[width=0.3\textwidth]{Uni Logo.png} 
    \vspace*{2cm}
    
    {\Large\bfseries Datenbanken Zusammenfassung\par}
    \vspace{1.5cm}
    
    \textbf{Peter Minor}\\
    Sommersemester 2025
    
    \vfill    
    \vspace{1.5cm}
    {\large \today\par}
\end{titlepage}

\tableofcontents

\newpage
\section{Kapitel 1: Einführung}
Sehr viel Geyappe über Datenbanken und Entwurfsmodelle, später.

\section{Kapitel 2: Datenbank-Modellierung}

\begin{block}{Modell}
Ein Modell ist ein abstrahiertes Abbild der Realität. Es hilft beim Verständnis, bei der Kommunikation und Simulation komplexer Sachverhalte. In der Datenbankmodellierung wird zwischen konzeptuellen, logischen und physischen Modellen unterschieden.
\end{block}

\subsection*{Entity-Relationship-Modell (ER)}

\begin{block}{Entitätstyp}
Ein Entitätstyp (auch Objekttyp) ist eine Klasse gleichartiger Objekte. Darstellung im ER-Diagramm: Rechteck.
\end{block}

\begin{block}{Attribut}
Ein Attribut beschreibt eine Eigenschaft eines Entitätstyps. Darstellung: Ellipse. Attribute können einfach, zusammengesetzt, mehrwertig oder berechnet sein.
\end{block}

\begin{block}{Beziehungstyp (Relationship)}
Ein Beziehungstyp stellt eine Relation zwischen Entitäten dar. Darstellung: Raute. Die Kardinalität (1:1, 1:n, m:n) beschreibt die Anzahl möglicher Zuordnungen.
\end{block}

\begin{block}{Schlüssel}
Ein Schlüssel ist ein Attribut (oder eine Attributkombination), das jede Entität eindeutig identifiziert. Starke Entitäten haben eigene Schlüssel; schwache Entitäten benötigen eine identifizierende Beziehung zu einer starken Entität.
\end{block}

\begin{block}{Partizipation}
Beschreibt, ob eine Entität zwingend an einer Beziehung teilnehmen muss:
\begin{itemize}
  \item \textbf{totale Partizipation}: jede Entität muss beteiligt sein
  \item \textbf{partielle Partizipation}: Beteiligung ist optional
\end{itemize}
\end{block}

\begin{block}{Spezialisierung \& Generalisierung (EER)}
\begin{itemize}
  \item \textbf{Spezialisierung}: Zerlegung eines Supertyps in Subtypen
  \item \textbf{Generalisierung}: Vereinigung ähnlicher Entitätstypen zu einem Supertyp
\end{itemize}
\end{block}

\begin{center}
\begin{tikzpicture}[node distance=2cm, every node/.style={scale=0.85}]
  % Entity types
  \node[draw, rectangle] (Student) {Student};
  \node[draw, rectangle, right=5cm of Student] (Vorlesung) {Vorlesung};
  \node[draw, rectangle, above=3cm of Vorlesung] (Professor) {Professor};

  % Attributes
  \node[draw, ellipse, below=1.2cm of Student] (MatrNr) {MatrNr};
  \node[draw, ellipse, below left=1.2cm and 0.5cm of Student] (SName) {Name};

  \node[draw, ellipse, below=1.2cm of Vorlesung] (VorlNr) {VorlNr};
  \node[draw, ellipse, below right=1.2cm and 0.5cm of Vorlesung] (Titel) {Titel};

  \node[draw, ellipse, above left=1.2cm and 0.5cm of Professor] (PersNr) {PersNr};
  \node[draw, ellipse, above=1.2cm of Professor] (PName) {Name};

  % Relationship types
  \node[draw, diamond, below=0.8cm of $(Student)!0.5!(Vorlesung)$] (hoert) {hört};
  \node[draw, diamond, right=2cm of Professor] (liest) {liest};

  % Connections
  \draw (Student) -- (hoert);
  \draw (Vorlesung) -- (hoert);

  \draw (Professor) -- (liest);
  \draw (Vorlesung) -- (liest);

  \draw (Student) -- (MatrNr);
  \draw (Student) -- (SName);

  \draw (Vorlesung) -- (VorlNr);
  \draw (Vorlesung) -- (Titel);

  \draw (Professor) -- (PersNr);
  \draw (Professor) -- (PName);
\end{tikzpicture}
\end{center}

\section{Kapitel 3: Das relationale Datenmodell}

\begin{block}{Relation}
Eine Relation ist eine Tabelle mit Attributen (Spalten) und Tupeln (Zeilen). Sie basiert auf dem mathematischen Konzept einer Menge von Tupeln.
\end{block}

\begin{block}{Primärschlüssel}
Ein Attribut oder Attributkombination, die ein Tupel eindeutig identifiziert.
\end{block}

\begin{block}{Fremdschlüssel}
Ein Attribut, das auf den Primärschlüssel einer anderen Relation verweist und referentielle Integrität sicherstellt.
\end{block}

\subsection*{Relationale Algebra}

\begin{block}{Selektion ($\sigma$)}
Filtert Tupel, die eine bestimmte Bedingung erfüllen. Beispiel:
\[
\sigma_{Note \geq 4}(\text{Pruefungen})
\]
\end{block}

\begin{block}{Projektion ($\pi$)}
Reduziert die Anzahl der Attribute. Beispiel:
\[
\pi_{Name, MatrNr}(\text{Studierende})
\]
\end{block}

\begin{block}{Vereinigung $\cup$ Schnitt $\cap$ Differenz $-$}
Klassische Mengenoperationen für Relationen mit gleichem Schema.
\end{block}

\begin{block}{Kartesisches Produkt ($\times$)}
Kombiniert zwei Relationen durch paarweise Tupelkombination.
\end{block}

\begin{block}{Join ($\bowtie$)}
Verknüpft zwei Relationen über gemeinsame Attribute. Spezialformen:
\begin{itemize}
  \item natürlicher Join
  \item theta-Join
  \item equi-Join
\end{itemize}
\end{block}

\begin{block}{Umbenennung ($\rho$)}
Benennung einer Relation oder ihrer Attribute neu, z.B. zur besseren Lesbarkeit von Ausdrücken.
\end{block}


Beispielhafte Relationen:
\begin{itemize}
  \item \textbf{Student}(\underline{MatrNr}, Name)
  \item \textbf{Professor}(\underline{PersNr}, Name)
  \item \textbf{Vorlesung}(\underline{VorlNr}, Titel)
  \item \textbf{hört}(\underline{MatrNr}, \underline{VorlNr}) \\
        Fremdschlüssel: MatrNr $\rightarrow$ Student, VorlNr $\rightarrow$ Vorlesung
  \item \textbf{liest}(\underline{PersNr}, \underline{VorlNr}) \\
        Fremdschlüssel: PersNr $\rightarrow$ Professor, VorlNr $\rightarrow$ Vorlesung
\end{itemize}

\section{Kapitel 4: Relationale Entwurfstheorie}

\begin{block}{Funktionale Abhängigkeit}
Eine Attributmenge $\alpha$ bestimmt eine andere Attributmenge $\beta$, geschrieben als:
\[
\alpha \rightarrow \beta
\]
gilt genau dann, wenn für alle Tupel $t_1$, $t_2$ gilt: $t_1[\alpha] = t_2[\alpha] \Rightarrow t_1[\beta] = t_2[\beta]$
\end{block}

\begin{block}{Schlüssel und Superschlüssel}
\begin{itemize}
  \item \textbf{Superschlüssel:} $\alpha$ ist Superschlüssel, wenn $\alpha \rightarrow R$
  \item \textbf{Kandidatenschlüssel:} Minimaler Superschlüssel
\end{itemize}
\end{block}

\begin{block}{Ziel der Normalisierung}
Die Normalisierung dient dazu, Redundanzen zu vermeiden und Anomalien (Einfüge-, Update-, Löschanomalien) zu verhindern. Dazu wird ein Relationenschema anhand funktionaler Abhängigkeiten in wohldefinierte Formen überführt.
\end{block}

\begin{block}{Überblick über die Normalformen}
\begin{itemize}
  \item \textbf{1NF (erste Normalform):} 
    Alle Attributwerte sind atomar (nicht weiter teilbar).
  \item \textbf{2NF (zweite Normalform):} 
    1NF erfüllt + jedes Nicht-Schlüsselattribut ist voll funktional abhängig vom gesamten Primärschlüssel.
  \item \textbf{3NF (dritte Normalform):} 
    2NF erfüllt + keine transitiven Abhängigkeiten von Nicht-Schlüsselattributen.
  \item \textbf{BCNF (Boyce-Codd Normalform):} 
    Für jede nicht-triviale funktionale Abhängigkeit $\alpha \rightarrow \beta$ gilt: $\alpha$ ist ein Superschlüssel.
\end{itemize}
\end{block}

\begin{block}{Vorgehen zur Normalisierung}
\begin{enumerate}
  \item Ermittele alle funktionalen Abhängigkeiten (FDs).
  \item Bestimme alle Schlüsselkandidaten.
  \item Prüfe die aktuelle Normalform.
  \item Zerlege die Relation bei Verstoß in mehrere Relationen:
  \begin{itemize}
    \item Zerlege so, dass jede FD in einer Relation vollständig erfüllt wird.
    \item Erhalte dabei die Verlustfreiheit und Abhängigkeitserhaltung.
  \end{itemize}
\end{enumerate}
\end{block}

\begin{block}{Beispiel: Normalisierung auf 3NF}
Gegeben sei folgende Relation:
\[
R(\underline{MatrNr}, Name, Studiengang, Fakultaet)
\]
mit den funktionalen Abhängigkeiten:
\begin{align*}
\text{F1: } & \text{MatrNr} \rightarrow \text{Name, Studiengang, Fakultaet} \\
\text{F2: } & \text{Studiengang} \rightarrow \text{Fakultaet}
\end{align*}

\textbf{Analyse:}
\begin{itemize}
  \item F1: MatrNr ist ein Schlüsselkandidat.
  \item F2: transitive Abhängigkeit: MatrNr $\rightarrow$ Studiengang $\rightarrow$ Fakultaet
  \item $\Rightarrow$ Verstoß gegen 3NF.
\end{itemize}

\textbf{Zerlegung in 3NF:}
\begin{itemize}
  \item $R_1(\underline{MatrNr}, Name, Studiengang)$
  \item $R_2(\underline{Studiengang}, Fakultaet)$
\end{itemize}

\textbf{Ergebnis:} Beide Relationen sind in 3NF, keine Redundanz, keine Anomalien.
\end{block}

\begin{block}{Anomalien}
Anomalien treten auf, wenn Relationen schlecht strukturiert sind – meist durch Redundanz und fehlende Trennung von unabhängigen Daten. Es gibt drei Hauptarten:
\begin{itemize}
  \item \textbf{Einfügeanomalie:} Daten können nicht eingefügt werden, ohne andere zu erzeugen
  \item \textbf{Updateanomalie:} Inkonsistenz bei mehrfacher Speicherung derselben Information
  \item \textbf{Löschanomalie:} Verlust nützlicher Informationen durch Löschung eines Tupels
\end{itemize}
\end{block}

\section{Kapitel 5: SQL - Structured Query Language}

Wir befinden uns in der Datenbank-Installation, also im Physischen Schemaentwurf.

\begin{block}{Historie}
  \begin{itemize}
    \item 1974: SEQUEL von IBM, Implementierung für System R
    \item 1983: SQL ist der Standard geworden
    \item 1986: SQL-86, bzw. SQL 1 $\Rightarrow$ erster ANSI und ISO-Standard
    \item 1992: SQL 2, deutliche Erweiterungen im Standard
    \item Weitere Revisionen:2000(SQL 3), 2003, 2006, 2008, 2011, 2016, 2023
  \end{itemize}
\end{block}

SQL dient als verschiedene Sprachen:
\begin{itemize}
  \item VDL, DDL, SDL zur Definition von Datenbanken
  \item DML(Datenmanipulationssprache), DCL(Datenkontrollsprache) zum Zugriff auf Datenbanken
\end{itemize}
SQL-Befehle:
\begin{center}
  \begin{longtable}{|p{4cm}|p{7cm}|}
    \hline
    \textbf{Befehl} & \textbf{Beschreibung} \\
    \hline
    \multicolumn{2}{|p{11cm}|}{SQL als DDL(Datendefinition)} \\
    \hline
    \texttt{CREATE SCHEMA} & Erstellt ein neues Schema in der Datenbank. \\
    \hline    
    Beispiel & \texttt{create schema Unternehmen authorization JSmith create table Projekt;} \\
    \hline
    Einfacher: & \texttt{PID int not null primary key,} \\
    & geht aber leider nicht mit zusammengesetzten Schlüsseln. \\
    \hline
    \texttt{CREATE Table} & Erstellt eine neue Tabelle im Schema. \\
    \hline
    Beispiel & \texttt{create table Projekt (} \\ & \texttt{PID int not null,} \\ & \texttt{Name varchar(50) not null, } \\ & \texttt{primary key(PID));} \\
    \hline
    \texttt{ALTER Table} & ändert die angegebene Tabelle. \\
    \hline
    \multicolumn{2}{|p{11cm}|}{Es gibt noch andere Verwendungen für \texttt{alter:}} \\
    \texttt{alter database} & ändert Eigenschaften der Datenbank. \\
    \texttt{alter view} & ändert die Definition einer Sicht \\
    \texttt{alter index} & modifiziert einen Index \\
    \texttt{alter user/role} & ändert die Rollen eines Benutzers \\
    \hline
    \texttt{Add} & Fügt eine Spalte zu einer Tabelle hinzu \\
    \hline
    Beispiel & \texttt{alter table Angestellte} \\
    & \texttt{ add foreign key (Abt) references Abteilung(Nummer);} \\
    \hline
    \texttt{drop} & Löscht das angegebene Objekt. Kann auf Schemen, Tabellen, Sichten, Constraints und Spalten angewendet werden. \\
    \hline
    Beispiel & \texttt{drop table Arbeitszeiten;} \\
    \hline
    \texttt{rename} & Ändert den Namen einer Tabelle \\
    \hline
    \multicolumn{2}{|p{11cm}|}{SQL als DML(Datenmanipulation und -abfrage)} \\
    \hline
    \texttt{select [..] from} & Wählt die gegebenen Spalten aus der Tabelle aus und gibt sie zurück \\
    \hline
    \multicolumn{2}{|p{11cm}|}{Durch z.B. \texttt{select 1.1*Gehalt} kann man Spaltenwerte in der Ausgabe anpassen.} \\
    \multicolumn{2}{|p{11cm}|}{Gleiches funktioniert mit +,- und / auf Zahlen.} \\
    \multicolumn{2}{|p{11cm}|}{Für Konkatinieren von Zeichenketten verwendet man \texttt{||}.} \\
    \hline
    \texttt{insert into} & fügt ein neues Tupel in eine Tabelle ein \\
    & überprüft automatisch die Vorgaben der Datenbank und weist ggf. zurück \\
    \hline
    Beispiel & \texttt{insert into Student (MNr, VName, NName, Fach) values (123456, 'Max', 'Mustermann', 'Informatik');} \\
    & Alle nicht angegebenen Infos werden zu NULL bzw. default. Bei SERIAL wird automatisch eingefügt. \\
    \hline
    \texttt{delete from [..]} & Löscht Tupel aus der angegebenen Tabelle. Where bestimmt, was gelöscht werden soll. \\
    & überprüft automatisch die Vorgaben der Datenbank und weist ggf. zurück \\
    \hline
    \texttt{update [..] set [..]} & setzt bei den Tupeln der Tabelle Attributwerte. \\
    &  kann mit where spezifiziert werden. \\
    \hline
    \texttt{merge into[..] using [..]} & Fügt zwei Tabellen zusammen, die gleiche Attribute erwarten. \\
    &  Durch \texttt{when matched} bzw. \texttt{when not matched} kann das Verhalten beim mergen bestimmt werden. \\
    \hline
    Beispiel & \texttt{merge into AllStudent c using Student a on AllStudent.MNr = Student.MNr} \\
    & \texttt{when matched then update set c.VName = a.VName, c.NName = a.NName...} \\
    & \texttt{when not matched then insert values (a.MNr, a.VName, a.NName, a.Fach);} \\
    \hline
    \texttt{create index [..] on [..]} & Erstellt einen Index auf die angegebene Tabelle. \\
    & Primärschlüssel erhalten automatisch einen Index \\
    \hline
    \texttt{begin\_transaction} & Startet eine Transaktion. \\
    \hline
    \texttt{end\_transaction} & Beendet eine Transaktion logisch \\
    \hline
    \texttt{commit} & Fügt die Ergebnisse einer Transaktion in den Datenbestand ein. \\
    \hline
    \texttt{abort} & Abbruch einer Transaktion. Änderungen werden verworfen. \\
    \hline
    \multicolumn{2}{|p{11cm}|}{Innerhalb einer Transaktion:} \\
    \hline
    \texttt{read\_item(X)} & Liest den Wert eines Datenobjekts X. \\
    \hline
    \texttt{write\_item(X)} & Schreibt den Wert einer Programmvariablen X in das entsprechende Datenobjekt. \\
    \hline
    \multicolumn{2}{|p{11cm}|}{SQL als VCL(Sichtendefinition)} \\
    \hline
    \texttt{create view [..] as select [..]} & Erstellt eine Sicht, die aus der Select-Abfrage resultiert. \\
    \hline
    \multicolumn{2}{|p{11cm}|}{SQL als DCL(Rechteverwaltung)} \\
    \hline
    \texttt{grant [..] on [..] to} &  Gibt das spezifitierte Recht an der spezifizierten Tabelle an die spezifizierten Nutzer.\\
    \hline
    \texttt{revoke [..] on [..] from} & Entzieht das spezifitierte Recht an der spezifizierten Tabelle von den spezifizierten Nutzern. \\
    \hline
  \end{longtable}
\end{center}
SQL-Keywords:
\begin{center}
  \begin{longtable}{|p{4cm}|p{7cm}|}
    \hline
    \textbf{Keyword} & \textbf{Beschreibung} \\
    \hline
    \multicolumn{2}{|p{11cm}|}{SQL als DDL(Datendefinition)} \\
    \hline
    \texttt{not null} & Attribut darf nicht leer sein. \\
    \hline
    \texttt{primary key} & Attribut ist Primärschlüssel der Tabelle. \\
    \hline
    \texttt{unique} & Attributwerte müssen eindeutig sein. \\
    \hline
    \texttt{check} & Ermöglicht komplexere Einschränkungen \\
    \hline
    \texttt{cascade} & ? \\
    \hline
    \texttt{set null} & Setzt die Referenz auf null \\
    \hline
    \texttt{set default} & Setzt die Referenz auf den Default-Wert \\
    \hline
    \texttt{No Action/Restrict} & ? \\
    \hline
    Beispiel & Constraints beispiel? \\
    \hline
    \texttt{foreign key} & Attribut verweist auf Primärschlüssel einer anderen Tabelle. \\
    \hline
    \texttt{references} & Definiert die referenzierte Tabelle und Spalte für den Fremdschlüssel. \\
    \hline
    Beispiel: & \texttt{foreign key (PID) references Projekt(PID)} \\
    \hline
    \texttt{to\_number} oder \texttt{to\_char} & Konvertiert Datentypen, z.B. von String zu Zahl oder umgekehrt. \\
    \hline
    Date, Time, Datetimeoffset, interval, year, day, second? & \\
    \hline
    \texttt{where} & filtert nach Bedingungen \\
    \hline
    Beispiel & \texttt{select * from Klausur where Note <= 4;} \\
    \hline
    \texttt{having} & filtert nach Bedingungen, nur auf Gruppen. Tritt nur zusammen mit \texttt{Group by} auf \\
    \hline
    Beispiel & \texttt{select * from Projekt, ArbeitetAn where Nummer = projNr group by Nummer, Name having count(*) > 2} \\
    \hline
    \texttt{and} & Verknüpft Bedingungen, alle müssen erfüllt sein \\
    \hline
    \texttt{or} & Verknüpft Bedingungen, mindestens eine muss erfüllt sein \\
    \hline
    \texttt{in} & Überprüft, ob ein Wert in einer Liste von Werten enthalten ist \\
    \hline
    Beispiel & \texttt{select * from Student where Durchschnittsnote in (0.7, 1.0, 1.7, 2.0);} \\
    \hline
    \texttt{order by} & Sortiert die Ergebnisse nach den angegebenen Spalten \\
    \hline
    \texttt{Asc} bzw. \texttt{desc} & Sortiert aufsteigend bzw. absteigend, Asc ist der Standardwert \\
    \hline
    Beispiel & \texttt{select * from Klausur order by Note desc;} \\
    \hline
    \texttt{group by} & Gruppiert die Ergebnisse nach den angegebenen Spalten \\
    \hline
    Beispiel & \texttt{select * from Belegung group by KursID;} \\
    \hline
    \texttt{distinct} & Entfernt doppelte Einträge aus dem Ergebnis \\
    & Aber ist teuer und braucht man nicht unbedingt.\\
    \hline
    Beispiel & \texttt{select distinct Alter from Student;} \\
    \hline
    \texttt{as} & Benennt die Spalte um \\
    Beispiel & \texttt{select Name as StudentName from Student;} \\
    & Auf Aliasse der äußeren Anfrage kann man innen zugreifen, anders herum aber nicht. \\
    \hline
    \texttt{count} & Zählt die Anzahl der Tupel \\
    \hline
    \texttt{sum} & Summe der Werte der Tupelattribute \\
    \hline
    \texttt{min} & kleinstes Tupelattribut \\
    \hline
    \texttt{max} & größtes Tupelattribut \\
    \hline
    \texttt{avg} & durschschnittlicher Wert der Tupelattribute \\
    \hline
    Beispiel & \texttt{select max(Gehalt) from Angestellte;} \\
    \hline
    \multicolumn{2}{|p{11cm}|}{In Kombination mit \texttt{group by} werden die Operationen \texttt{count, sum, min, max} und \texttt{avg} jeweils auf die einzelnen Gruppen angewendet.} \\
    \hline
    \texttt{like} & Vergleicht Zeichenketten \\
    \hline
    Beispiel & \texttt{select * from Student where Name like 'T \_ \_';} \\
    & sucht alle Studierenden raus, die einen Namen mit drei Buchstaben haben, der mit T anfängt\\
    & \texttt{select * from Student where Name like 'T\%';} \\
    & sucht alle Studierenden raus, die einen Namen haben, der mit T anfängt \\
    \hline
    \texttt{between} & Überprüft, ob ein Wert in einem Intervall liegt \\
    \hline
    \texttt{exists} & Überprüft, ob das Ergebnis einer Unterabfrage nicht leer ist \\
    \hline
    \texttt{not} & Negiert eine Bedingung \\
    \hline
    \texttt{unique} & überprüft, ob eine Multimenge Duplikate enthält \\
    \hline
    \texttt{is null} bzw. \texttt{is not null} & Überprüft, ob ein Attributwert NULL ist. = NULL ist nicht möglich! \\
    \hline
  \end{longtable}
\end{center}

\begin{block}{SQL als DDL}
  \begin{itemize}
    \item Schema, Tabellen, Datentypen, Constraints definieren
    \item Strukturelle Änderungen mittels \texttt{drop}, \texttt{alter}
    \item SCHEMA:
    \begin{itemize}
      \item Namensraum in DB
      \item Hat eindeutigen Namen
      \item Hat Autorisierungsbezeichner
      \item Beschreibt jedes im Schema enthaltene Objekt
      \begin{itemize}
        \item Relationen
        \item Wertebereiche
        \item Restriktionen
        \item Sichten
        \item Zugriffsrechte
      \end{itemize}
    \end{itemize}
    \item \texttt{information\_schema} enthält Metadaten über die Datenbank
  \end{itemize}
\end{block}

\begin{block}{Übergang von relationelem Schema zu SQL Schema}
  \begin{itemize}
    \item Name der Relation wird zum Tabellennamen
    \item Attribute werten untereinander geschrieben(Datentypen angeben)
    \item Bei einem Schlüssel \texttt{primary key} hinterschreiben
    \item Bei zusammengesetzten Schlüsseln \texttt{primary key (A, B)} angeben
    \item Für IDs ist \texttt{serial} als Datentyp sinnvoll
    \item Fremdschlüssel werden mit \texttt{foreign key} gekennzeichnet
  \end{itemize}
\end{block}
Beispiel:
\begin{itemize}
  \item \textbf{Student}(\underline{Matrikelnummer}, Name, Studiengang)
  \item \textbf{Kurs}(\underline{KursID}, Titel, Dozent)
  \item \textbf{Belegung}(\underline{Matrikelnummer}, \underline{KursID}, Note)
\end{itemize}
Wird folgendes SQL-Schema:
\begin{lstlisting}
-- Tabelle: Student
CREATE TABLE Student (
    Matrikelnummer INT PRIMARY KEY,
    Name VARCHAR(100),
    Studiengang VARCHAR(100)
);

-- Tabelle: Kurs
CREATE TABLE Kurs (
    KursID SERIAL PRIMARY KEY,
    Titel VARCHAR(100),
    Dozent VARCHAR(100)
);

-- Tabelle: Belegung
CREATE TABLE Belegung (
    Matrikelnummer INT,
    KursID INT,
    Note DECIMAL(3,1),
    PRIMARY KEY (Matrikelnummer, KursID),
    FOREIGN KEY (Matrikelnummer) REFERENCES Student(Matrikelnummer),
    FOREIGN KEY (KursID) REFERENCES Kurs(KursID)
);
\end{lstlisting}

\begin{block}{SQL als DML}
  \begin{itemize}
    \item Daten manipulieren und abfragen
    \item Es können Duplikate auftreten, falls nicht gewünscht \texttt{distinct} nutzen
    \item Es wird zuerst Join dann Gruppierung und dann Aggregation durchgeführt
    \item Abfragen können auch Unterabfragen enthalten, also verschachtelt sein.
  \end{itemize}
\end{block}

\begin{block}{Umsetzung der Operationen der relationalen Algebra in SQL}
  \begin{center}
    \begin{tabular}{|p{4cm}|p{7cm}|}
      \hline
      \textbf{Operation} & \textbf{SQL-Äquivalent} \\
      \hline
      Kartesisches Produkt & \texttt{select * from A, B;} \\
      \hline
      Join & \texttt{select * from A inner join b on <Bedingung>;} \\
      \hline
      Natürlicher Join & \texttt{select * from A natural join B;} \\
      \hline
      Outer Join & \texttt{select * from A left outer join B on <Bedingung>;} \\
      & man kann auch \texttt{right} oder \texttt{full} nutzen. \\
      \hline
      Join mit sich selber mit Alias & \texttt{select * from Angestellte A, Angestellte B where A.ID = B.Vorgesetzte;} \\
      \hline
      Hinweis & wenn zweimal ein gleichnamiges Attribut existiert, kann man mit z.B. A.ID und B.ID darauf zugreifen \\
      & Auf Aliasse der äußeren Anfrage kann man innen zugreifen, anders herum aber nicht. \\
      \hline
      Vereinigung & \texttt{select * from A union select * from B;} \\
      \hline
      Schnitt & \texttt{select * from A intersect select * from B;} \\
      \hline
      Differenz & \texttt{select * from A minus select * from B;} \\
      \hline
      \multicolumn{2}{|p{11cm}|}{Bei Vereinigung, Schnitt und Differenz werden Duplikate entfernt} \\
      \hline
    \end{tabular}
  \end{center}
\end{block}

\begin{block}{SQL als VDL(Verwaltung der Sichten)}
  Eine Sicht ist eine virtuelle Tabelle, die aus einer Abfrage resultiert.
  \begin{itemize}
    \item Können, müssen aber nicht in der Datenbank gespeichert werden
    \item Werden immer aktuell gehalten
    \item Können wie Tabellen abgefragt werden
    \item Manipulation oft nicht möglich(non-updatable views)
  \end{itemize}
\end{block}

\begin{block}{SQL als DCL(Verwaltung der Zugriffsrechte)}
  \begin{itemize}
    \item \texttt{grant} und \texttt{revoke} für Rechteverwaltung
    \item Rechte können auf Objekte wie Tabellen, Sichten, Prozeduren angewendet werden
    \item Rechte: SELECT, INSERT, UPDATE, DELETE, EXECUTE
    \item Beispiel: \texttt{grant select on Tabelle to Benutzer;}
  \end{itemize}
\end{block}

\begin{block}{Datentypen in SQL}
  \begin{center}
    \begin{tabular}{|p{4cm}|p{7cm}|}
      \hline
      \textbf{Datentyp} & \textbf{Beschreibung} \\
      \hline
      \texttt{Integer/int, smallint} & Ganze Zahlen, smallint kleinere Zahlen ($\Rightarrow$ kleinerer Speicherbedarf) \\
      \hline
      \texttt{Float, Real, Double precision} & Gleitkommazahlen, Approximativ. Double precision für mehr Genauigkeit \\
      \hline
      \texttt{Decimal(i, j), Numeric(i, j)} & Feste Dezimalzahlen, i: Stellen insgesamt, j: Stellen nach dem Komma \\
      \hline
      \texttt{Serial} & Automatisch inkrementierende Ganzzahl, oft für Primärschlüssel \\
      \hline
      \texttt{Char(n), Varchar(n)} & Text, bei Char wird bei kürzerer Eingabe mit ' ' aufgefüllt, bei Varchar nicht \\
      \hline
      \texttt{create domain} & Definiert einen benutzerdefinierten Datentyp \\
      \hline
    \end{tabular}
  \end{center}
\end{block}

\subsection*{Programmiermethoden in SQL}
\begin{block}{Zugriff auf die DB}
  Der Zugriff auf die Datenbank kann von verschiedenen Gruppen erfolgen:
  \begin{itemize}
    \item Administratoren: Die Befehle von den Administratoren werden in der Regel direkt auf der Datenbank ausgeführt.
    \item Anwendungen: Anwendungen nutzen in der Regel eine Schnittstelle (API) der Datenbank, um auf sie zuzugreifen.
    \item Gelegentliche Nutzer: Die Befehle von gelegentlichen Nutzern werden in der Regel über eine interaktive Anfrage passieren, die erst einen Übersetzer durchlaufen, um dann auf der Datenbank ausgeführt zu werden.
  \end{itemize}
\end{block}

\begin{block}{SQL-Programmiermethoden}
  Es gibt mehrere Möglichkeiten, wie ein Anwendungsprogramm auf eine Datenbank zugreifen kann:
  \begin{itemize}
    \item Direkter Aufruf
    \begin{itemize}
      \item Aufruf von SQL-Befehlen direkt im Programm
    \end{itemize}
    \item Embedded/Dynamic SQL
    \begin{itemize}
      \item SQL Wird in die Programmiersprache eingebettet
      \item SQL-Befehle werden dynamisch zur Laufzeit generiert
    \end{itemize}
    \item Module Language
    \begin{itemize}
      \item SQL wird in Module ausgelagert, die in der Programmiersprache aufgerufen werden
    \end{itemize}
    \item Call-Level APIs
    \begin{itemize}
      \item Standardisierte Schnittstellen (z.B. ODBC, JDBC) für den Datenbankzugriff
      \item Der Programmierer sieht kein SQL mehr (Mappings)
    \end{itemize}
  \end{itemize}
\end{block}

\begin{block}{impedance mismatch}
  \begin{itemize}
    \item Relationales Modell wird von objektorientieren Programmiersprachen nicht unterstützt
    \item SQL basiert auf Mengen, OO-Programmiersprachen auf Objekten
    \item Keine Pointer o.Ä.
    \item Lösung: Embedded SQL
  \end{itemize}
\end{block}

\begin{block}{Embedded SQL}
  \begin{itemize}
      \item Problem wird (teilweise) umgangen, indem Variablen zwischen SQL und der Programmiersprache 'geteilt' werden
      \item \texttt{exec sql begin declare section;} bzw. \texttt{[..]end[..];}
      \item Darin können Variablen deklariert werden:
      \item \texttt{char var1[20]; int var2;}
      \item Dann kann in die Variablen geschrieben werden:
      \item \texttt{exec sql insert into [..] values (:var1, :var2);}
      \item Außerdem kann gelesen werden:
      \item \texttt{exec sql select [..] into :var1 from [..];}
      \item Variable \texttt{SQLSTATE} enthält den Status der letzten SQL-Anweisung und ggf. Fehlercodes
    \end{itemize}
\end{block}

\begin{block}{Cursor in Embedded SQL}
  Trotzdem bleibt bestehen: Das Ergebnis von SQL-Abfragen sind meistens Mengen. Lösung: Cursors
  \begin{itemize}
    \item Cursors sind Zeiger auf eine Ergebnismenge
    \item Sie ermöglichen es, durch die Ergebnismenge zu iterieren
    \item Beispiel:
    \begin{lstlisting}
    exec sql begin declare section;
    char var1[20];
    char SQLSTATE[6];
    exec sql end declare section;
    exec sql declare c1 cursor for select VName
                              from Student;
    exec sql open c1;
    while(true) {
        exec sql fetch c1 into :var1;
        if (SQLSTATE == '02000') break;
        // Verarbeite var1
    }
    exec sql close c1;
    \end{lstlisting}
  \end{itemize}
\end{block}
Ursprünglich wurde für Java SQLJ benutzt, mittlerweile ist das aber veraltet.
\begin{block}{Dynamic SQL}
  \begin{itemize}
    \item Standard für dynamische SQL-Abfragen in Programmen
    \item Also keine Deklaration vorab
    \item Zwei Möglichkeiten:
    \item Execute Immediate: Direkte Ausführung eines SQL-Befehls
    \item Prepare and Execute: SQL-Befehl wird vorbereitet und dann (mehrfach) ausgeführt
    \item Großer Nachteil: SQL Injection möglich, wenn nicht richtig abgefangen wird
  \end{itemize}
\end{block}

\begin{block}{Module Language}
  \begin{itemize}
    \item Trennung von SQL und Anwendungsprogramm
    \item Modul enthält SQL-Befehle und Deklarationen
    \item Anwendungsprogramm ruft Modul auf
  \end{itemize}
\end{block}

\begin{block}{Call-Level APIs}
  \begin{itemize}
    \item Standardisierte Schnittstellen für den Datenbankzugriff
    \item Beispiel: ODBC, SQL/CLI, JDBC
    \item Programmierer sieht kein SQL mehr, sondern nur die API-Funktionen
    \item Mappings zwischen Objekten und Relationen
  \end{itemize}
\end{block}

\begin{block}{ORM: Mappings zwischen Objekten und Relationen}
  \begin{itemize}
    \item Alles nicht perfekt, da Objekte und Relationen unterschiedliche Konzepte sind
    \item ORM (Object-Relational Mapping) versucht, diese Lücke zu schließen
    \item Mappings zwischen Objekten und Relationen
    \item Framework verbirgt SQL komplett und bietet objektorientierte API
  \end{itemize}
\end{block}

\section{Kapitel 6: Anfrageverarbeitung}

\begin{block}{Motivation}
  \begin{itemize}
    \item DBMS muss viele Anfragen möglichst schnell und minimalen Ressourcen verarbeiten
    \item $\Rightarrow$ effiziente Anfrageverarbeitung notwendig
  \end{itemize}
\end{block}

\begin{block}{DBMS Aufbau}
  \begin{itemize}
    \item Zuerst gehen die Anfragen an die Anfrageverarbeitung, die aus einem Operator-Evaluierer und einem Optimierer besteht
    \item Danach durchlaufen sie die Speicherung, zuerst die Dateiverwaltungs- und Zugriffsmethoden
    \item Danach den Puffer-Verwalter und den Verwalter für externen Speicherbedarf
    \item Diese Interagieren mit dem Transaktionsmanagement, das aus einem Transaktionsverwalter, einem Sperrverwalter und einem Wiederherstellungsverwalter besteht
    \item Danach geht die Anfrage an die Datenbank, die in der Realität aus Dateien und Daten und Indices besteht
  \end{itemize}
  Schaubild Kapitel 6, Seite 4
  \begin{itemize}
    \item Die Verwaltung eines DBMS ähnelt sehr der eines Betriebssystems, daher
    \item schaltet es häufig Betriebsdienstsysteme aus, um gegenseitige Störungen zu verhindern
    \item Das DBMS weiß mehr über die Zugriffsmuster, was Prefetching(s.u. In der Praxis) ermöglicht
  \end{itemize}
\end{block}

\subsection*{Speicherung}

\begin{block}{Speicherung}
  \begin{itemize}
    \item In großen Datenbanken sind die Daten zu groß, um in den Hauptspeicher zu passen
    \item Speicherung soll eine große Menge an Speicherplatz liefern
    \item Dabei  soll der Zugriff für möglichst geringe Kosten möglichst schnell sein
    \item Die Daten sollen gesichtert sein, Verlust der Daten ist nicht akzeptabel
    \item In einem normalen Computer wird das folgendermaßen umgesetzt:
    \begin{tabular}{|p{4cm}|p{3cm}|p{2cm}|}
      \hline
      \textbf{Speichertyp} & \textbf{Kapazität} & \textbf{Latenz} \\
      \hline
      CPU(Register) & Bytes & < 1 ns \\
      \hline
      Cache-Speicher & Kilo-/Megabytes & < 10 ns \\
      \hline
      Hauptspeicher(RAM) & Gigabytes & 20-100 ns \\
      \hline
      Flash-Speicher/SSD & Terabytes & 30-250 $\mu$s \\
      \hline
      Festplatte/HDD & Tera-Petabytes & 3-10ms \\
      \hline
      Bandautomat & Petabytes & variiert \\
      \hline
    \end{tabular}
  \end{itemize}
\end{block}

\begin{block}{Magnetische (Fest-)Platten}
  \begin{itemize}
    \item Arme werden auf bestimmte Spur bewegt, Platte dreht konstant
    \item Spur: Kreis auf de Oberfläche der Platte
    \item Sektor: Eine Spur wird in Sektoren unterteilt, die kleinste adressierbare Einheit
    \item Block: Mehrere Sektoren zusammen in eine logische Einheit gefasst
    \item Zugriffszeit besteht aus:
    \begin{itemize}
      \item Suchzeit $t_s$: Zeit, um den Arm auf die richtige Spur zu bewegen
      \item Wartezeit $t_r$: Zeit, bis der Block unter dem Lesekopf ist
      \item Lese- bzw. Schreibzeit $t_{tr}$
      \item Gesamte Zugriffszeit $t_a = t_s + t_r + t_{tr}$
    \end{itemize}
    \item Sequentieller Zugriff, bei dem die Blöcke direkt hintereinander liegen ist schneller als Wahlfreier Zugriff
    \item Sehr viel schneller.
  \end{itemize}
\end{block}

\begin{block}{Speichernetzwerk(SAN)}
  \begin{itemize}
    \item Speichernetzwerk, das aus mehreren Festplatten bzw. Servern mit jeweils mehreren Festplatten besteht
    \item Zeigt sich aber als 'logische Platten' an das DBMS
    \item Vorteile: Hardwarebeschleunidung, Redundanz(Fehlertoleranz), einfachere Verwaltung, Flexibilität
    \item Alternativ: Cloud-Speicher, der über das Internet zugänglich ist
    \item System kostet mehr und ist Langsamer(Redundanz von bis zu 1s), aber ist zuverlässiger
  \end{itemize}
\end{block}

\subsection*{Verwaltung}

\begin{block}{Abstrahierung der Technischen Details vom Speicher(Seiten)}
  \begin{itemize}
    \item Eine 'Seite' ist eine logische Speichereinheit(4-64 KB) für die Restlichen Komponenten
    \item Die Seitennummer weist auf die physische Adresse der Seite hin
    \begin{itemize}
      \item Betriebssystemdatei inkl. Versatz
      \item Kopf-Sektor-Spur von Festplatte
      \item Angabe für ein Bandgerät und -nummer inkl. Versatz
    \end{itemize}
  \end{itemize}
\end{block}

\begin{block}{leere Seiten}
  \begin{itemize}
    \item \texttt{insert} sucht leere Seite zum Einfügen
    \item \texttt{delete} gibt die Seite wieder frei
    \item Leere Seiten müssen Persistenz gespeichert werden
    \begin{itemize}
      \item Als Liste von leeren Seiten(Hinzufügen, wenn Seite leer wird, entfernen, wenn Seite alloziert wird)
      \item Als Bitmap, Bit p wird umgeklappt, wenn die Seite (de-)alloziert wird
    \end{itemize}
  \end{itemize}
\end{block}

\subsection*{Puffer}
\begin{block}{Puffer-Verwalter}
  \begin{itemize}
    \item Vermittelt zwischen externem Speicher(Festplatten etc) und internem Speicher(Hauptspeicher)
    \item Verwaltet Teil des Hauptspeichers(buffer pool)
    \item Externe Seiten werden in den Puffer geladen
    \item \texttt{pin} und \texttt{unpin}, um Seiten anzufordern und freizugeben
    \item Hier wird die Seitennummer angegeben und beim freigeben auch, ob die Seite bearbeitet wurde
    \item Wenn die Seite bereits im Puffer ist, wird direkt die Referenz zurückgegeben
    \item Wenn die Seite nicht im Puffer ist, wird sie geladen und die Referenz zurückgegeben
    \item Es wird gespeichert, wie oft eine Seite angefordert wurde, damit benutze Seiten immer im Puffer bleiben
    \item Wenn der Puffer voll ist, muss eine Ersetzungsstrategie angewendet werden
  \end{itemize}
\end{block}

\begin{block}{Ersetzungsstrategien}
  Es wird ausgewählt, welche Seite aus dem Puffer entfernt wird, wenn eine neue Seite geladen werden soll.
  \begin{itemize}
    \item LRU: Seite mit dem am längsten zurückliegenden unpin
    \item LRU-k: k-letztes unpin, sonst wie LRU
    \item MRU: Seite mit dem jüngsten unpin
    \item Random: Zufällige Seite
    \item [..]
  \end{itemize}
  Problem: Seite muss Pincount = 0 haben, aber was ist, wenn es eine solche Seite nicht gibt?
\end{block}

\begin{block}{In der Praxis}
  \begin{itemize}
    \item Anfragen werden 'vorhergesagt', Seiten werden im Puffer gehalten, wenn sie wahrscheinlich benötigt werden(Prefetching)
    \item Fixierungs- und Verdrängungsempfehlungen von höherem Code, wenn dieser Weiß, dass eine Seite länger benötigt wird oder wahrscheinlich nicht mehr
  \end{itemize}
\end{block}

\subsection*{Zugriff}
\begin{block}{Datenbank-Dateien}
  \begin{itemize}
    \item Der Inhalt von Seiten ist für die Seitenverwaltung nicht relevant
    \item DBMS verwaltet die Tabellen von Tupeln, Indexstrukturen, ...
    \item Eine Datei besteht aus einer oder mehreren Seiten
    \item jede Seite speichert einen oder mehrere Datensätze
    \item Ein Datensatz entspricht einem Tupel
  \end{itemize}
\end{block}

\begin{block}{Heap-Dateien}
  \begin{itemize}
    \item Datensätze werden in willkürlicher$^*$ Ordnung gespeichert
    \item Umsetzung: Verkettete Liste von Seiten, Problem: Man muss viele Seiten durchsuchen(und auch Laden), bis die richtige Seite gefunden wurde
    \item Alternative: Verzeichnis von Seiten, ist mit Zusatzaufwand für das Verzeichnis verbunden
  \end{itemize}
  $^*$Bei der Speicherung von Datensätzen gibt es mehrere Möglichkeiten, die 'richtige' Seite zu finden:
  \begin{tabular}{|p{4cm}|p{6.5cm}|}
    \hline
    \textbf{Methode} & \textbf{Beschreibung} \\
    \hline
    Append only & Datensatz wird immer an die aktuelle Seite angefügt, wenn diese voll ist, wird eine neue Seite angelegt. \\
    \hline
    Best-fit & Datensatz wird auf die Seite geschrieben, wo die 'kleinste Lücke' ist, in die der Satz noch passt \\
    & man muss erst alle Seiten durchsuchen, um die beste zu finden \\
    \hline
    First-fit & Datensatz wird auf die erste Seite geschrieben, wo genug Platz ist \\
    \hline
    Next-fit & Wie first-fit, aber die Suche beginnt bei der letzten einfügeoperation \\
    \hline
  \end{tabular}
\end{block}

\begin{block}{Inhalt einer Seite}
  \begin{itemize}
    \item Jeder Datensatz hat eine Datensatz-Kennung, die genau beschreibt, wo sich dieser befindet
    \item Typisch: Seitennummer und Slot, Slots beginnen bei 0, mit fester Slotgröße
    \item Suche dann innerhalb der Seite mit \texttt{slotnr * slotsize}
    \item Die Seite hat einen Header, der mit einer Bitmap markiert, welche Slots belegt bzw. gültig sind
    \item Löschung eines Datensatzes: Slot wird als ungültig markiert, die Datensatz-Kennung ändert sich nicht
    \item Ggf. haben Datensätze unterschiedliche Längen, diese werden dann ans Ende der Seite gepackt und ein Slot-Verzeichnis wird verwendet
    \item Das Verzeichnis enthält die Startadresse und Länge jedes Datensatzes
    \item Dadurch kann die Datensatz-Kennung auf die Adresse im Slot-Verzeichnis zeigen und das Feld auf der Seite verschoben werden, ohne dass sich die Kennung ändert
    \item Das Slot-Verzeichnis wird am Anfang der Seite gespeichert
  \end{itemize}
\end{block}

\begin{block}{Alternative Seiteneinteilung}
  \begin{itemize}
    \item Row-Store:
    \begin{itemize}
      \item Tupel werden immer zusammen gespeichert
      \item Vorteil: Schneller Zugriff auf komplette Tupel, vor allem bei \texttt{select * from Student where Name = 'Max';} sinnvoll
    \end{itemize}
    \item Column-Store:
    \begin{itemize}
      \item Es wird immer ein Attribut zusammen gespeichert, dafür dann für alle Tupel
      \item Vorteil: Schneller Zugriff auf einzelne Attribute, vor allem bei \texttt{select avg(Note) from Klausur;} sinnvoll
    \end{itemize}
  \end{itemize}
  Diese Konzepte lassen sich auch kompinieren.
\end{block}

\subsection*{Indexierung}

\begin{block}{Effiziente Evaluierung einer Anfrage}
  \begin{itemize}
    \item \texttt{[..] where plz between 48159 and 48163;}
    \item Wird Ausgewertet, indem nach plz sortiert wird und danach mit binärer Suche der startwert gefunden und bis zum Endwert iteriert wird
    \item Problem: Bei der Suche sind die Datensätze wahrscheinlich nicht auf einer Seite(das ist das Prinzip von binärer Suche)
    \item Lösungsidee: (Binär-)Bäume(kp, da wurde fast nichts zu gesagt?)
  \end{itemize}
\end{block}

\begin{block}{ISAM-Indexierung}
  \begin{itemize}
    \item Aufteilung in Datenseiten und Indexseiten
    \item Indexseiten enthalten Schlüssel und Zeiger auf die Datenseiten
    \item Datenseiten trotzdem sortiert
    \item Hunderte Einträge pro Indexseite $\Rightarrow$ kleine Baumtiefe
    \item Felder fester Länge, Navigation mittels Versatz
    \item Binärsuche auf Indexseiten möglich
    \item Indexeinträge:
    \begin{itemize}
      \item Bestehen aus Schlüssel k, der für die Suche verwendet wird
      \item Seperator p, der Referenz auf die nächste Index- oder die Datenseite enthält
      \item Seperator p ist der kleinste Schlüssel, der größer als k ist
      \item p$_0$ ist kleiner als der kleinste Schlüssel in der Indexseite
    \end{itemize}
    \item Braucht totale Ordnung der Schlüssel
    \item Indexseiten sind in einem Baum organisiert, der die Suche effizient macht
    \item Sucht zuerst mittels Binärsuche in der 'Wurzelseite' nach dem Seperator p$_i$, sodass k$_i \leq$ k < k$_{i+1}$
    \item p$_i$ ist dann der Zeiger auf die nächste Seite, die durchsucht werden muss
    \item Die Suche wird rekursiv fortgesetzt, bis eine Datenseite erreicht ist
    \item Dann wird auf der Datenseite nach k gesucht und ab da Sequentiell gelesen
    \item Vorteile: Zugriff auf Daten schnell, da nur wenige Seiten gelesen werden müssen, viel Sequientieller Zugriff
    \item Nachteile: Zusätzlicher Speicherbedarf für Indexseiten
    \item Für (einigermaßen) statische Daten ist ISAM sehr gut geeignet. Warum?
  \end{itemize}
\end{block}

\begin{block}{Aktualisierungen bei ISAM}
  \begin{itemize}
    \item Löschen: Datensatz über Index suchen, anschließend aus der Datenseite löschen
    \item Einfügen: auf passende Datenseite navigieren und Datensatz einfügen
    \item Problem: Was ist, wenn die Seite voll ist?
    \begin{itemize}
      \item Im Vorhinein Platz lassen
      \item Überlauf-Seite einfügen
      \item Vorteil: Index bleibt statisch
      \item Nachteil: Sequentielle Ordnung der Datensätze ist nicht mehr gegeben
    \end{itemize}
    \item Typisch sind 20\% Freiraum
    \item Da Indexseiten statisch sind, ist keine Zugriffskoordination(bei Mehrbenutzerbetrieb) nötig
  \end{itemize}
\end{block}

\begin{block}{Zugriffskoordination}
  Sperrt den (Zeitgleichen) Zugriff, besonders nahe an der Wurzel.
\end{block}

\begin{block}{B$^+$-Bäume}
  \begin{itemize}
    \item Ähnlich zu ISAM, aber dynamische Indexseiten
    \item Dominieren in der Praxis
    \item Keine Überlauf-Ketten
    \item Balancierung wird Aufrecht erhalten(50\% minimale Besetzung der Knoten, bei 67\% auch B$^*$-Baum genannt)
    \item Also hat jeder Nicht-Wurzelknoten zwischen d und 2d Einträge, wobei d die Ordnung des Baumes ist
    \item Hinzufügen und Löschen wird angemessen behandelt
    \item Referenzierte Datenblätter nicht in sequentieller Ordnung
    \item Blätter des Indexbaums sind zu doppelt verketteter Liste verbunden
    \item Es gibt drei Varianten von B$^+$-Bäumen, sie unterscheiden sich darin, was in den Blättern gespeichert wird:
    \begin{enumerate}
      \item Vollständiger Datensatz: Die Blätter sind die Datenseiten
      \item Paare <k, rid>, sortiert nach k mit rid als Referenz auf Datensatz
      \item Paare <k, \{rid$_1$, rid$_2$, ...\}>, wobei alle rids den Suchschlüssel k haben
    \end{enumerate}
    \item Variante 2 wird am häufigsten verwendet, nehmen wir ab hier an.
    \item $\Rightarrow$ Die Datenblätter sind nicht sequentiell geordnet
    \item Es gibt geclusterte B$^+$-Bäume, bei denen die Datensätze Sequentiell geordnet sind
    \item Suche findet wie bei ISAM statt, die Suche bricht aber schon bei den Blättern ab
  \end{itemize}
\end{block}

\begin{block}{Einfügen in B$^+$-Bäume}
  \begin{itemize}
    \item B$^+$-Baum soll balanciert bleiben
    \item Suche die Blattseite, auf der der Eintrag eingefügt werden soll
    \item Falls die Seite noch genug Platz hat(maximal 2d-1 Einträge), wird der Eintrag eingefügt
    \item Sonst: Teile die Blattseite in Zwei Hälften, wobei die linke Hälfte d Einträge und die rechte Hälfte d-1 Einträge enthält
    \item Füge die Referenz auf die neue Seite in den Elternknoten ein
    \item Wird rekursiv bis zur Wurzel durchgeführt
    \item Falls die Wurzel geteilt wird, wird eine neue Wurzel erstellt, der Baum wächst in der Höhe
  \end{itemize}
  \centering
  \begin{tikzpicture}[level distance=2.5cm,
      sibling distance=2cm,
      every node/.style={rectangle split, rectangle split parts=2, draw, minimum width=1.2cm, text centered},
      leaf/.style={rectangle split, rectangle split parts=3, draw, minimum width=1.8cm, text centered},
      edge from parent/.style={draw,-latex},
      level 2/.style={sibling distance=3cm},
    ]

    \node (root) {10}
      child {node [leaf] {1 \nodepart{two} 4 \nodepart{three} 7}}
      child {node [leaf] {11 \nodepart{two} 13 \nodepart{three} 15}};

    \begin{scope}[xshift=7cm]
    \node (newroot) {7 \nodepart{two} 10}
      child {node [leaf] {1 \nodepart{two} 4}}
      child {node [leaf] {7 \nodepart{two} 9}}
      child {node [leaf] {11 \nodepart{two} 13 \nodepart{three} 15}};
    \end{scope}

    \draw[->, thick] (2,-1.5) -- (5,-1.5);
    \node[draw=none, rectangle split parts=1] at (3.5,-1.5) [anchor=south] {Aufspaltung der Blattseite};
  \end{tikzpicture}
  \textbf{Schritt:} Einfügen von \textbf{9}
\end{block}

\begin{block}{Löschen aus B$^+$-Bäumen}
  \begin{itemize}
    \item B$^+$-Baum soll balanciert bleiben
    \item Suche die Blattseite, auf der der Eintrag gelöscht werden soll
    \item Falls die Seite noch genug Einträge hat(min. d+1), wird der Eintrag gelöscht
    \item Sonst: Falls eine der Nachbarseiten mehr als d Einträge hat, wird ein Eintrag von der Nachbarseite übernommen
    \item Danach wird der Index angepasst
    \item Falls beide Nachbarseiten nur d Einträge haben, verschmelzt die Seite mit einer der Nachbarseiten
    \item Der Eintrag in der Elternseite, der auf die Seite zeigt, wird gelöscht
    \item Das Verschmelzen(oder Umverteilen) wird dann ggf. rekursiv bis zur Wurzel weitergeführt
  \end{itemize}
  In der Praxis wird das Verschmelzen meist nicht durchgeführt und die Minimumregel aufgeweicht
\end{block}

\begin{block}{Hash-basierte Indexierung}
  \begin{itemize}
    \item Daten werden in mittels einer Hash-Funktion auf Seiten, sogenannte 'Buckets' verteilt
    \item Hash-Funktion berechnet einen Hashwert für den Schlüssel
    \item Bei statischem Hashing: Feste Anzahl an Buckets, die Hash-Funktion ist konstant
    \item Im Bucket sind die Datensätze oder rids gespeichert
    \item Suche sehr schnell, da nur der Bucket durchsucht werden muss
    \item Hashing ist besonders geeignet für Gleichheitsabfragen(z.B. \texttt{where VName='Max';})
  \end{itemize}
\end{block}

\begin{block}{Dynamisches Hashing}
  \begin{itemize}
    \item statisches Hashing hat das Problem der Wahl der Anzahl der Buckets.
    \begin{itemize}
      \item Zu wenige Buckets: Viele Kollisionen, langsame Suche
      \item Zu viele Buckets: Speicherplatzverschwendung
    \end{itemize}
    \item Lösung: Anzahl der Buckets wird dynamisch angepasst
    \item Dann wird die Speicherung langsamer, weil sich eventuell die Hash-Funktion ändert
  \end{itemize}
\end{block}

Indexierung verschnellert den Zugriff auf Daten, aber braucht mehr Speicher und die Indexierung kostet auch Zeit.

\subsection*{Anfragebeantwortung}

\begin{block}{Ausführungspläne}
  \begin{itemize}
    \item Eine Anfrage wird in einen Ausführungsplan übersetzt
    \item Der Ausführungsplan beschreibt, wie die Anfrage ausgeführt wird
    \item Er besteht aus Operatoren, die auf den Daten arbeiten
    \item Ausführungspläne sind nicht immer eindeutig
  \end{itemize}
\end{block}

\begin{block}{Sortieren}
  \begin{itemize}
    \item Sortierung kommt in Datenbanken häufig vor (\texttt{asc, desc}, für B$^+$-Bäume etc.)
    \item Wie kann aber etwas sortiert werden, was nicht in den Hauptspeicher passt?
    \item $\Rightarrow$ Zwei-Wege-Mischsortierung
  \end{itemize}
\end{block}

\begin{block}{Zwei-Wege-Mischsortierung}
  \begin{itemize}
    \item Sortierung in mehreren Durchgängen mit minimal 3 Pufferseiten(Schneller mit mehr)
    \item Zeitaufwand ist $O(n \log n)$.
    \item Startet mit dem Sortieren von jeder einzelnen Seite für sich
    \item Dann werden rekursiv zwei Sortierte 'Pakete' zusammengeführt, es ist immer nur eine Seite der 'Pakete' im Puffer
    \item Um $n$ Seiten zu sortieren, werden $2 \cdot n \cdot (1 + \lceil log_2n \rceil)$ I/O-Operationen verwendet(bei 3 Pufferseiten)
    \item Wie wird das bei mehr Pufferseiten weniger?
    \begin{itemize}
      \item Zwei Möglichkeiten(kombinierbar):
      \item Reduktion des initialen 'Pakets', indem mehrere Seiten gleichzeitig sortiert werden
      \begin{itemize}
        \item Mit $k$ Seiten im Puffer können $k$ Seiten gleichzeitig sortiert werden
        \item Dadurch wird die Anzahl der I/O-Operationen reduziert:
        \[2 \cdot n \cdot (1 + \lceil log_2\frac{n}{k} \rceil)\]
      \end{itemize}
      \item Reduktion der Anzahl der Durchgänge durch das Sortieren von mehr als 2 'Paketen'
      \begin{itemize}
        \item Mit $k$ Pufferseiten können $k-1$ Pakete gleichzeitig sortiert werden
        \item Dadurch wird die Anzahl der I/O-Operationen weiter reduziert:
        \[2 \cdot n \cdot (1 + \lceil log_{k-1}\frac{n}{k} \rceil)\]
      \end{itemize}
    \end{itemize}
    \item In der Praxis meist genug Speicherplatz, um die Sortierung in wenigen Durchgängen zu machen
  \end{itemize}
\end{block}
[Hier fehlt was zum externen Mischsortieren]?

\begin{block}{Join-Implementierung}
  \begin{itemize}
    \item Intuitive Herangehensweise: Erst Kreuzprodukt, dann Filterung nach Bedingung
    \item Problem: Zwischenergebnis sehr groß
    \item Lösung: Join als geschachtelte Schleife
    \begin{itemize}
      \item Für jedes Tupel der ersten Relation wird die zweite Relation durchsucht
      \item Dann wird geprüft, ob für die jeweilige Kombination die Join-Bedingung erfüllt ist
      \item Wenn ja, wird das Tupel in das Ergebnis aufgenommen
      \item Problem davon: Sehr viele wahlfreie Zugriffe $\Rightarrow$ ineffizient
    \end{itemize}
    \item Besser: Blockweiser Join mit Schleifen
    \begin{itemize}
      \item Iteriert auf Blöcken, die dann sequentiell gelesen werden können.
      \item Diese werden dann auf die intuitive Weise gejoined und das Ergebnis angehängt.
      \item Wichtig: der Join muss im Hauptspeicher ausführbar sein.
      \item $\Rightarrow$ mehr Speicherplatzverbrauch, aber weniger langsam
    \end{itemize}
    \item Wenn die Bedingung ein Gleihheitsprädikat ist, kann eine Hash-Tabelle für den äußeren Block deutlich beschleunigen.
    \item Weil man nur das Bucket mit der Gleichheit durchsuchen muss
    \item Wenn bereits ein Index für eine Relation vorhanden ist, die mit der Bedingung verträglich ist(SARGable), kann diese Relation auch nach innen geschoben und dann damit gearbeitet werden.
    \item Alternative: Hash-Join
    \begin{itemize}
      \item R und S werden anhand einer Hash-Funktion partitioniert
      \item Dann wird join(R$_i$, S$_i$) für alle i berechnet werden (einfacher)
      \item Anzahl der Partitionen sollte so gewählt werden, dass der Join im Hauptspeicher berechnet werden kann
    \end{itemize}
  \end{itemize}
\end{block}

\begin{block}{Gruppierung + texttt{unique}-Behandlung}
  \begin{itemize}
    \item Herausforderung: identische Datensätze in einer Datei finden
    \item Entweder bzgl. Gruppierungsattributen oder bzgl aller Attribute
    \item Umsetzung mit Sortierung oder Hash-Join
  \end{itemize}
\end{block}

\begin{block}{Selektion und Projektion}
  Projektion $\pi$
  \begin{itemize}
    \item Entfernen nicht benötigter Spalten
    \item Eliminierung von Duplikaten
  \end{itemize}
  Selektion $\sigma$
  \begin{itemize}
    \item Ablaufen aller Datensätze
    \item Eventuell Sortierung oder Index ausnutzen
  \end{itemize}
\end{block}

\begin{block}{Pipelining}
  \begin{itemize}
    \item Bisher: Operatoren verarbeiten ganze Dateien
    \item Führt zu langen Antwortzeiten etc.
    \item Alternativ könnte der Operator direkt seine Ergebnisse an den nächsten senden
    \item Wichtig: größe der Brocken, die weitergegeben werden
    \item Ausführung wird dadurch deutlich schneller
  \end{itemize}
\end{block}

\begin{block}{Blockierende Operatoren}
  \begin{itemize}
    \item Pipelining funktioniert nicht für alle Operatoren, z.B.
    \begin{itemize}
      \item Misch-Sortierung
      \item Gruppierung, Eliminierung von Duplikaten, Max/Min
    \end{itemize}
    \item Solche Operatoren bekommen immer gesamtes Zwischenergebnis
  \end{itemize}
\end{block}

\subsection*{Anfrageoptimierung}

\begin{block}{Anfrageoptimierung}
  \begin{itemize}
    \item Ausführungspläne wichtigste Entscheidung
    \item Welche Implementierung von Join-Operatoren?
    \item Welche Blockgößen, Pufferallokation?
    \item Soll ein Index angelegt werden?
    \item Einige Optimierungen können unabhängig von den Daten erfolgen
    \begin{itemize}
      \item Selektionsprädikate früh anwenden, einfacher machen
      \item Geschachtelte Anfragen entschachteln, Joins explizit machen
      \item Duplikat-Eliminierung vermeiden
    \end{itemize}
    \item Datenabhängige Optimierung macht der Optimiser
    \begin{itemize}
      \item Kostenbasiert auf Basis der Daten, größen der DB
    \end{itemize}
  \end{itemize}
\end{block}

\section{Kapitel 7: Transaktionen}

\begin{block}{Transaktion}
  \begin{itemize}
    \item logische Verarbeitungseinheit auf einer DB
    \item typischerweise mehrere Operationen
    \item werden mit \texttt{begin\_transaction;} gestartet
    \item und mit \texttt{end\_transaction;} beendet
    \item müssen mit \texttt{commit;} physisch durchgeführt werden oder mit \texttt{abort} abgebrochen werden
    \item ACID-Eigenschaften:
    \begin{itemize}
      \item Atomicity: Alles oder nichts
      \item Consistency: Vorher alles ok, hinterher alles ok
      \item Isolation: Jede/r denkt, er/sie sei alleine auf der DB
      \item Durability: Transaktion bestätigt? Dann sind die Daten sicher
    \end{itemize}
    \item Fehler in Transaktionen
    \begin{itemize}
      \item Lost Update: Zwei Transaktionen greifen auf dasselbe Datenobjekt zu
      \item Dirty Read: Eine Transaktion, die später abgebrochen wird, schreibt ein Datenobjekt, dass dann von einer anderen Transaktion gelesen wird
      \item Ghost-Update: Aggregation wird von einer Transaktion berechnet, eine andere Transaktion aktualisiert davon betroffene Datenobjekte
      \item Unrepeatable Read: Eine Transaktion liest ein Datenobjekt zweimal, dazwischen wird es von einer anderen Transaktion aktualisiert
    \end{itemize}
  \end{itemize}
\end{block}

\subsection*{Scheduling}
\begin{block}{Scheduling}
  \begin{itemize}
    \item Bei großen Mengen von Transaktionen sollten die Transaktionen nicht nacheinander, sondern nebenläufig ausgeführt werden
    \item Aber es soll keine Anomalien auftreten. Das ist die Aufabe eines Schedulers
    \item Konflikte zwischen zwei Operationen liegen vor, wenn
    \begin{itemize}
      \item Sie zu unterschiedlichen Transaktionen gehören
      \item Sie auf dasselbe Datenobjekt zugreifen
      \item und mindestens eine Operation eine Schreiboperation ist
    \end{itemize}
    \item Nicht konfliktäre Operationen können gleichzeitig ausgeführt werden
  \end{itemize}
\end{block}

\begin{block}{Korrektheitsprüfung mit Serialisierungsgraphen}
  \begin{itemize}
    \item Gerichteter Graph mit allen Transaktionen, Kanten nur von Transaktionen zu anderen Transaktionen, bei denen eine Operation, die im Konflikt steht früher ausgeführt wird.
    \item Wenn der Graph keine Zyklen enthält, ist S serialisierbar, sonst nicht
  \end{itemize}
\end{block}

\subsection*{Sperrverwaltung}

\end{document}